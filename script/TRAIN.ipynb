{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51d94ad4416da926",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef3047e5636b8ed5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T21:55:05.573699200Z",
     "start_time": "2024-04-25T21:54:58.064911100Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ef3047e5636b8ed5",
    "outputId": "3bcda65a-7787-4378-d96f-b2ad01386b0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.utils\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import Resize, RandomCrop, ToTensor, Compose\n",
    "from torchvision.utils import save_image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from util import get_hole, get_mask, crop\n",
    "from generator import Generator\n",
    "from discriminator import Discriminator\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "MIN_HOLEW, MAX_HOLEW = 96, 128\n",
    "MIN_HOLEH, MAX_HOLEH = 96, 128\n",
    "EPOCH_G = 20\n",
    "EPOCH_D = 15\n",
    "EPOCH_M = 100\n",
    "batch_size = 64\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "iVcwcxkUfaBc",
   "metadata": {
    "id": "iVcwcxkUfaBc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8424d2d94f3a9d37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T21:55:38.264688100Z",
     "start_time": "2024-04-25T21:55:26.000583400Z"
    },
    "id": "8424d2d94f3a9d37"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Dataset not found or corrupted. You can use download=True to download it",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m tsfm \u001b[38;5;241m=\u001b[39m Compose([Resize(\u001b[38;5;241m256\u001b[39m), RandomCrop((\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m)), ToTensor()])\n\u001b[1;32m----> 3\u001b[0m training_data \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCelebA\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtsfm\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m test_data \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mCelebA(\n\u001b[0;32m     10\u001b[0m     root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m     split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     12\u001b[0m     download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     13\u001b[0m     transform\u001b[38;5;241m=\u001b[39mtsfm\n\u001b[0;32m     14\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Taochen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datasets\\celeba.py:88\u001b[0m, in \u001b[0;36mCelebA.__init__\u001b[1;34m(self, root, split, target_type, transform, target_transform, download)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload()\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_integrity():\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found or corrupted. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     90\u001b[0m split_map \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     95\u001b[0m }\n\u001b[0;32m     96\u001b[0m split_ \u001b[38;5;241m=\u001b[39m split_map[verify_str_arg(split\u001b[38;5;241m.\u001b[39mlower(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m))]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Dataset not found or corrupted. You can use download=True to download it"
     ]
    }
   ],
   "source": [
    "\n",
    "tsfm = Compose([Resize(256), RandomCrop((256, 256)), ToTensor()])\n",
    "\n",
    "training_data = datasets.CelebA(\n",
    "    root=\"../data\",\n",
    "    split='train',\n",
    "    download=False,\n",
    "    transform=tsfm\n",
    ")\n",
    "test_data = datasets.CelebA(\n",
    "    root=\"../data\",\n",
    "    split='test',\n",
    "    download=False,\n",
    "    transform=tsfm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f04dcc53e1a7bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T21:56:11.971699100Z",
     "start_time": "2024-04-25T21:56:10.714673500Z"
    },
    "id": "69f04dcc53e1a7bd"
   },
   "outputs": [],
   "source": [
    "\n",
    "# calculating mean pixel value of the training set\n",
    "mpv = torch.tensor((0.50925811, 0.42336759, 0.37791181)).view(1, 3, 1, 1).to(device) #precomputed mean value\n",
    "# mpv = np.zeros((3,))\n",
    "# for x in training_data:\n",
    "#    r = x[0][0]\n",
    "#    g = x[0][1]\n",
    "#    b = x[0][2]\n",
    "#   mpv += (torch.mean(r), torch.mean(g), torch.mean(b))\n",
    "# mpv /= len(training_data)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch = torch.cat([sample[0].unsqueeze(0) for sample in batch], dim=0)\n",
    "    return batch\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "generator = Generator().to(device)\n",
    "optimizer = optim.Adadelta(generator.parameters(), lr=0.1)\n",
    "\n",
    "GPATH = \"../model/gen-mutual-20-loss13.787893346045166.pth\"\n",
    "if GPATH is not None:\n",
    "  checkpoint = torch.load(GPATH)\n",
    "  generator.load_state_dict(checkpoint['model_state_dict'])\n",
    "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "discriminator = Discriminator().to(device)\n",
    "OptimizerD = optim.Adadelta(discriminator.parameters(), lr=0.01)\n",
    "DPATH = \"../model/dis-14-loss-2.8606153897929893e-06.pth\"\n",
    "if DPATH is not None:\n",
    "  checkpoint = torch.load(DPATH)\n",
    "  discriminator.load_state_dict(checkpoint['model_state_dict'])\n",
    "  OptimizerD.load_state_dict(checkpoint['optimizer_state_dict'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260053071875a157",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The above code imports all the necessary modules, defining the constants and load the data/model using pytorch. Note that the mean pixel value of the training set is pre-calculated to save time. The training uses standard CelebA dataset with its pre-defined training and test set. In total, during the training phase the generator is trained 20 times alone, discriminator is trained 15 times alone, and they are both trained 21 times mutually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4i5fAKcpMEe5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "id": "4i5fAKcpMEe5",
    "outputId": "ead3e875-adcc-4f7b-e5c8-fb26f7a0d565"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/20: 100%|██████████| 2544/2544 [18:15<00:00,  2.32it/s, loss=0.00398]\n",
      "Epoch 1/20: 100%|██████████| 2544/2544 [18:17<00:00,  2.32it/s, loss=0.00342]\n",
      "Epoch 2/20: 100%|██████████| 2544/2544 [18:16<00:00,  2.32it/s, loss=0.00616]\n",
      "Epoch 3/20: 100%|██████████| 2544/2544 [18:19<00:00,  2.31it/s, loss=0.0033]\n",
      "Epoch 4/20: 100%|██████████| 2544/2544 [18:18<00:00,  2.32it/s, loss=0.00453]\n",
      "Epoch 5/20: 100%|██████████| 2544/2544 [18:19<00:00,  2.31it/s, loss=0.00363]\n",
      "Epoch 6/20: 100%|██████████| 2544/2544 [18:17<00:00,  2.32it/s, loss=0.00373]\n",
      "Epoch 7/20: 100%|██████████| 2544/2544 [18:21<00:00,  2.31it/s, loss=0.00344]\n",
      "Epoch 8/20: 100%|██████████| 2544/2544 [18:21<00:00,  2.31it/s, loss=0.00303]\n",
      "Epoch 9/20: 100%|██████████| 2544/2544 [18:21<00:00,  2.31it/s, loss=0.0041]\n",
      "Epoch 10/20: 100%|██████████| 2544/2544 [18:21<00:00,  2.31it/s, loss=0.0025]\n",
      "Epoch 11/20:   0%|          | 10/2544 [00:04<20:00,  2.11it/s, loss=0.00295]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-16a1ae054b97>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch}/{EPOCH_G}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m       \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m       \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0mloss_tot\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH_G):\n",
    "  generator.train()\n",
    "  loop = tqdm(train_dataloader, desc=\"Generator\")\n",
    "  loss_tot = 0\n",
    "  for x in loop:\n",
    "      x = x.to(device)\n",
    "      shape = (x.shape[0], 1, x.shape[2], x.shape[3])\n",
    "      hole = get_hole((random.randint(MIN_HOLEW, MAX_HOLEW),\n",
    "                        random.randint(MIN_HOLEH, MAX_HOLEH)))\n",
    "      mask = get_mask(shape, hole).to(device)\n",
    "      net_in = x - x * mask + mpv * mask\n",
    "      input = torch.cat((net_in, mask), dim=1)\n",
    "      out = generator(input)\n",
    "      loss = nn.functional.mse_loss(x*mask, out*mask)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      optimizer.zero_grad()\n",
    "      loop.set_description(f\"Epoch {epoch}/{EPOCH_G}\")\n",
    "      loop.set_postfix(loss=loss.item())\n",
    "      loop.update()\n",
    "      loss_tot += loss.item()\n",
    "  torch.save({'epoch': epoch,\n",
    "        'model_state_dict': generator.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "            }, \"/content/model/regen-\" + str(epoch) + \"-loss-\"+str(loss_tot/len(loop))+\".pth\")\n",
    "  loop.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72d00323d3533fd",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YpFzUljy3d2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T21:57:52.210678400Z",
     "start_time": "2024-04-25T21:57:50.234936200Z"
    },
    "id": "YpFzUljy3d2b"
   },
   "outputs": [],
   "source": [
    "GEN_TEST_PATH = \"../model/regen-10-loss-0.003284191969820919.pth\"\n",
    "generator_test = Generator().to(device)\n",
    "checkpoint_test = torch.load(GEN_TEST_PATH)\n",
    "generator_test.load_state_dict(checkpoint_test['model_state_dict'])\n",
    "with torch.no_grad():\n",
    "  x = next(iter(test_dataloader)).to(device)\n",
    "  shape = (x.shape[0], 1, x.shape[2], x.shape[3])\n",
    "  hole = get_hole((random.randint(MIN_HOLEW, MAX_HOLEW),\n",
    "                    random.randint(MIN_HOLEH, MAX_HOLEH)))\n",
    "  mask = get_mask(shape, hole).to(device)\n",
    "  x = x - x * mask + mpv * mask\n",
    "  input = torch.cat((x, mask), dim=1)\n",
    "  out = generator_test(input)\n",
    "  imgs = torch.cat((x.cpu(), out.cpu()), dim=0)\n",
    "  save_image(imgs, \"../result/test1.jpg\", nrow=len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf95eda5a4d11a02",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We show the result of training generator only. We can see it's pretty blurred since only mse loss is used\n",
    "![result of generator](../result/test1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NykNIc0OyJ99",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NykNIc0OyJ99",
    "outputId": "a1661e67-99e8-4018-fc57-64148f17d24e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/15: 100%|██████████| 2544/2544 [13:35<00:00,  3.12it/s, loss=9.44, lossC=1.44e-5, lossD=9.31e-5]\n",
      "Epoch 1/15: 100%|██████████| 2544/2544 [13:36<00:00,  3.11it/s, loss=0.101, lossC=1.25e-5, lossD=6.66e-5]\n",
      "Epoch 2/15: 100%|██████████| 2544/2544 [13:37<00:00,  3.11it/s, loss=0.0538, lossC=3.53e-5, lossD=2.69e-5]\n",
      "Epoch 3/15: 100%|██████████| 2544/2544 [13:38<00:00,  3.11it/s, loss=0.0361, lossC=5.59e-6, lossD=1.2e-5]\n",
      "Epoch 4/15: 100%|██████████| 2544/2544 [13:37<00:00,  3.11it/s, loss=0.0276, lossC=7.95e-6, lossD=8.68e-6]\n",
      "Epoch 5/15: 100%|██████████| 2544/2544 [13:38<00:00,  3.11it/s, loss=0.0213, lossC=2.51e-6, lossD=2e-6]\n",
      "Epoch 6/15: 100%|██████████| 2544/2544 [13:39<00:00,  3.11it/s, loss=0.0174, lossC=1.69e-6, lossD=7.26e-6]\n",
      "Epoch 7/15: 100%|██████████| 2544/2544 [13:37<00:00,  3.11it/s, loss=0.0152, lossC=3.55e-6, lossD=7.1e-6]\n",
      "Epoch 8/15: 100%|██████████| 2544/2544 [13:39<00:00,  3.11it/s, loss=0.0134, lossC=1.09e-6, lossD=5.55e-6]\n",
      "Epoch 9/15: 100%|██████████| 2544/2544 [13:37<00:00,  3.11it/s, loss=0.0122, lossC=1.87e-6, lossD=2.93e-6]\n",
      "Epoch 10/15: 100%|██████████| 2544/2544 [13:38<00:00,  3.11it/s, loss=0.0103, lossC=1.87e-6, lossD=2.18e-6]\n",
      "Epoch 11/15: 100%|██████████| 2544/2544 [13:36<00:00,  3.11it/s, loss=0.00963, lossC=6.11e-6, lossD=3.03e-6]\n",
      "Epoch 12/15: 100%|██████████| 2544/2544 [13:37<00:00,  3.11it/s, loss=0.00874, lossC=1.51e-6, lossD=5.5e-6]\n",
      "Epoch 13/15: 100%|██████████| 2544/2544 [13:37<00:00,  3.11it/s, loss=0.00807, lossC=4.62e-6, lossD=1.9e-6]\n",
      "Epoch 14/15: 100%|██████████| 2544/2544 [13:37<00:00,  3.11it/s, loss=0.00728, lossC=1.34e-6, lossD=1.66e-5]\n"
     ]
    }
   ],
   "source": [
    "BCEloss = nn.BCELoss()\n",
    "\n",
    "for epoch in range(EPOCH_D):\n",
    "  discriminator.train()\n",
    "  loop = tqdm(train_dataloader, desc=\"Discriminator\")\n",
    "  loss_tot = 0\n",
    "  for x in loop:\n",
    "    shape = (x.shape[0], 1, x.shape[2], x.shape[3])\n",
    "    x = x.to(device)\n",
    "    holeC = get_hole((128, 128))\n",
    "    maskC = get_mask(shape, holeC).to(device)\n",
    "    net_input = x - x * maskC + mpv * maskC\n",
    "    inputC = torch.cat((net_input, maskC), dim=1)\n",
    "    outC = generator(inputC)\n",
    "    global_inputC = outC.detach()\n",
    "    local_inputC = crop(global_inputC, holeC)\n",
    "    resultC = discriminator((local_inputC.to(device), global_inputC.to(device)))\n",
    "    lossC = BCEloss(resultC, torch.zeros((len(x), 1), dtype=torch.float).to(device))\n",
    "\n",
    "    holeD = get_hole((128,128))\n",
    "    local_inputD = crop(x, holeD)\n",
    "    resultD = discriminator((local_inputD.to(device), x))\n",
    "    lossD = BCEloss(resultD, torch.ones((len(x), 1), dtype=torch.float).to(device))\n",
    "\n",
    "    loss_overall =  (lossC +  lossD)/2\n",
    "    loss_overall.backward()\n",
    "    loss_tot += loss_overall.item()\n",
    "    OptimizerD.step()\n",
    "    OptimizerD.zero_grad()\n",
    "    loop.set_description(f\"Epoch {epoch}/{EPOCH_D}\")\n",
    "    loop.set_postfix({'loss':loss_tot, 'lossC': lossC.item(), 'lossD': lossD.item()})\n",
    "    loop.update()\n",
    "  torch.save({'epoch': epoch,\n",
    "        'model_state_dict': discriminator.state_dict(),\n",
    "        'optimizer_state_dict': OptimizerD.state_dict(),\n",
    "        'loss': loss_overall,\n",
    "            }, \"/content/model/dis-\" + str(epoch) + \"-loss-\"+str(loss_tot/len(loop))+\".pth\")\n",
    "  loop.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "o1S-KHDA2Vo3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "id": "o1S-KHDA2Vo3",
    "outputId": "e298a04f-be21-4a5f-a060-9c93182e566e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/100: 100%|██████████| 2544/2544 [23:24<00:00,  1.81it/s, lossG=13.3, lossD=0.00387]\n",
      "Epoch 1/100: 100%|██████████| 2544/2544 [23:19<00:00,  1.82it/s, lossG=12.8, lossD=0.00314]\n",
      "Epoch 2/100:  67%|██████▋   | 1695/2544 [15:33<07:47,  1.82it/s, lossG=8.53, lossD=0.00331]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-39da23060f43>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch}/{EPOCH_M}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'lossG'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlossG_tot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lossD'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlossD_overall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m   torch.save({'epoch': epoch,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BCEloss = nn.BCELoss()\n",
    "for epoch in range(EPOCH_M):\n",
    "  lossG_tot = 0\n",
    "  generator.train()\n",
    "  discriminator.train()\n",
    "  alpha = torch.tensor(0.004, dtype=torch.float32).to(device)\n",
    "  loop = tqdm(train_dataloader, desc=\"Mutual training\")\n",
    "  for x in loop:\n",
    "    x = x.to(device)\n",
    "    shape = (x.shape[0], 1, x.shape[2], x.shape[3])\n",
    "    holeC = get_hole((128, 128))\n",
    "    maskC = get_mask(shape, holeC).to(device)\n",
    "    net_input = x - x * maskC + mpv * maskC\n",
    "    inputC = torch.cat((net_input, maskC), dim=1)\n",
    "    outC = generator(inputC)\n",
    "    global_inputC = outC.detach()\n",
    "    local_inputC = crop(global_inputC, holeC)\n",
    "    resultC = discriminator((local_inputC.to(device), global_inputC.to(device)))\n",
    "    lossC = BCEloss(resultC, torch.zeros((len(x), 1), dtype=torch.float).to(device))\n",
    "\n",
    "    holeD = get_hole((128,128))\n",
    "    local_inputD = crop(x, holeD)\n",
    "    resultD = discriminator((local_inputD.to(device), x))\n",
    "    lossD = BCEloss(resultD, torch.ones((len(x), 1), dtype=torch.float).to(device))\n",
    "    lossD_overall =  (lossC +  lossD) * alpha / 2\n",
    "    lossD_overall.backward()\n",
    "    OptimizerD.step()\n",
    "    OptimizerD.zero_grad()\n",
    "\n",
    "\n",
    "    lossG = nn.functional.mse_loss(x*maskC, outC*maskC)\n",
    "    lossG_tot += lossG.item()\n",
    "    outputD1 = discriminator((crop(outC, holeC).to(device), outC.to(device)))\n",
    "    lossG_overall = (lossG + alpha * BCEloss(outputD1, torch.ones((len(x), 1), dtype=torch.float).to(device)))/2\n",
    "    lossG_overall.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    loop.set_description(f\"Epoch {epoch}/{EPOCH_M}\")\n",
    "    loop.set_postfix({'lossG': lossG_tot, 'lossD': lossD_overall.item()})\n",
    "    loop.update()\n",
    "  torch.save({'epoch': epoch,\n",
    "        'model_state_dict': discriminator.state_dict(),\n",
    "        'optimizer_state_dict': OptimizerD.state_dict(),\n",
    "        'loss': lossD_overall,\n",
    "            }, \"/content/model/dis-mutual-\" + str(epoch)+\".pth\")\n",
    "  torch.save({'epoch': epoch,\n",
    "        'model_state_dict': generator.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': lossG_overall,\n",
    "            }, \"/content/model/gen-mutual-\" + str(epoch)+ \"-loss\" + str(lossG_tot) +\".pth\")\n",
    "  loop.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EY3RZWJDSx_p",
   "metadata": {
    "id": "EY3RZWJDSx_p"
   },
   "source": [
    "# **For inference**\n",
    "\n",
    "After training them mutually, we can do inference. The test result will be shown in the main jupyter notebook called project.ipynb, please refer to that notebook for inference."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
